# ğŸ¯ Quick Reference - AI Agent Development Framework

**Version:** 1.2.0 | **Updated:** February 14, 2026 | **Part:** 2/8  
**Status:** Production Ready âœ…  
**Purpose:** Fast lookup for formulas, checklists, matrices, and decision trees

---

## ğŸ“ Purpose

This file is your **reference desk** for quick answers. No long explanations, just:
- **7-step process** (memorize this)
- **Risk scoring formula** (0-17 scale)
- **Guardrails by risk level** (what to enable)
- **Deployment matrix** (where to run it)
- **Essential checklists** (what to verify)
- **Easy swapping patterns** (code examples)

**When to use:** During design decisions, implementation, deployment. Pinned in your browser.

---

## ğŸ—ºï¸ Quick Navigation

- [Super Quick Start](#-super-quick-start-5-min)
- [The 7-Step Process](#-the-7-step-process-memorize-this)
- [Risk Scoring Formula](#-risk-scoring-formula-0-17-scale)
- [Auto-Enabled Guardrails](#-auto-enabled-guardrails-by-risk-level)
- [Deployment Platform Matrix](#-deployment-platform-matrix-february-2026)
- [Architecture Decision Matrix](#-architecture-decision-matrix)
- [Easy Swapping Patterns](#-easy-swapping-patterns-no-rewrites)
- [Testing Requirements](#-testing-requirements)
- [Deployment Checklist](#-deployment-checklist)
- [Troubleshooting Quick Fixes](#-troubleshooting-quick-fixes)
- [Success Indicators](#-success-indicators)

---

## ğŸ”— Related Files

**Before this:** [00_START_HERE.md](./00_START_HERE.md) (Choose your path)  
**After this:** [02_COMPLETE_GUIDE.md](./02_COMPLETE_GUIDE.md) (Deep dive on any section)  
**For Claude setup:** [04_AI_ASSISTANT_INTEGRATION.md](./04_AI_ASSISTANT_INTEGRATION.md)  
**For daily workflow:** [05_CLAUDE_CONTEXT_AND_BUGS.md](./05_CLAUDE_CONTEXT_AND_BUGS.md)

---

## âš¡ Super Quick Start (5 min)

```bash
1. Calculate your risk score (see formula below)
2. Choose your guardrails (see table below)
3. Choose your platform (see matrix below)
4. Reference this file when making decisions
5. Read 00_START_HERE.md for context
```

---

## ğŸ¯ The 7-Step Process (Memorize This)

**Use this sequence for EVERY project:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 1: DISCOVERY                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â–¡ What problem are we solving?              â”‚
â”‚ â–¡ Who uses it? How?                         â”‚
â”‚ â–¡ What does success look like?              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 2: RISK SCORING (0-17)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â–¡ Input Risk (0-5): How dangerous is input? â”‚
â”‚ â–¡ Output Risk (0-5): Impact of wrong result?â”‚
â”‚ â–¡ Data Sensitivity (0-4): PII/Financial?    â”‚
â”‚ â–¡ Model Risk (0-3): LLM autonomy?           â”‚
â”‚ â–¡ TOTAL = Sum (determines everything next) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 3: GUARDRAILS                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â–¡ 0-4 (LOW): Basic validation               â”‚
â”‚ â–¡ 5-10 (MEDIUM): + Rate limiting            â”‚
â”‚ â–¡ 11-17 (HIGH): + Human approval            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 4: ARCHITECTURE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â–¡ <1K users: Monolith                       â”‚
â”‚ â–¡ 1K-10K: Modular monolith                  â”‚
â”‚ â–¡ 10K+: Multi-container microservices       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 5: TOOLING STRATEGY                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â–¡ Internal: Local Adapters (fast)           â”‚
â”‚ â–¡ External: MCP Bridges (safe)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 6: IMPLEMENTATION                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â–¡ Phase 1: Core + Unit tests (60%)          â”‚
â”‚ â–¡ Phase 2: Integration + Security (20%)     â”‚
â”‚ â–¡ Phase 3: Observability + OpenTelemetry (20%)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 7: DEPLOY & MONITOR                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â–¡ Infrastructure (Terraform)                â”‚
â”‚ â–¡ CI/CD Pipeline                            â”‚
â”‚ â–¡ Observability (OTEL traces)               â”‚
â”‚ â–¡ Iterate based on data                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Risk Scoring Formula (0-17 Scale)

### Calculate Your Score

```
TOTAL RISK = Input Risk + Output Risk + Data Sensitivity + Model Risk

Min: 0 (no risk)
Max: 17 (extreme risk)
```

### Input Risk (0-5)

| Score | Scenario | Example |
|-------|----------|---------|
| **0** | No input | Batch jobs, read-only systems |
| **1** | Dropdown selection | Predefined categories |
| **2** | Structured text | Forms with validation |
| **3** | Open-ended input | User questions, feedback |
| **4** | Code/commands | Script generation, shell access |
| **5** | Direct API/DB access | Raw SQL queries, unfiltered database calls |

### Output Risk (0-5)

| Score | Scenario | Example |
|-------|----------|---------|
| **0** | Read-only | Logs, dashboards, reports |
| **1** | Informational | Summaries, explanations |
| **2** | Recommendations | Suggestions, rankings |
| **3** | Decisions | Status changes, approvals |
| **4** | Automated actions | Data updates, API calls |
| **5** | Critical | Financial transactions, medical decisions |

### Data Sensitivity (0-4)

| Score | Data Type | Examples |
|-------|-----------|----------|
| **0** | Public | News, Wikipedia, public repos |
| **1** | Internal | Company docs, internal wikis |
| **2** | PII | Names, emails, addresses |
| **3** | Sensitive PII | Phone, SSN, ID numbers |
| **4** | Extreme | Medical records, financial accounts |

### Model Risk (0-3) â€” NEW in v1.2.0

| Score | LLM Type | Autonomy Level |
|-------|----------|----------------|
| **0** | None | No LLM, deterministic only |
| **1** | Constrained | Classification, simple generation |
| **2** | Complex | Reasoning chains, code generation |
| **3** | Autonomous | Uses tools, takes actions, multi-step |

### Risk Score Thresholds

```
0-4:   LOW      â†’ Basic guardrails
5-10:  MEDIUM   â†’ Standard guardrails
11-17: HIGH     â†’ Comprehensive guardrails + isolation
```

### Example Calculations

**Example 1: Research Agent**
```
Input:     3 (user questions)
Output:    2 (summaries)
Data:      0 (public sources)
Model:     2 (reasoning)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: 7 (MEDIUM) â† Rate limit, injection checks
```

**Example 2: Autonomous Code Generator**
```
Input:     4 (open specs)
Output:    4 (production code)
Data:      1 (internal examples)
Model:     3 (autonomous, tools)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: 12 (HIGH) â† Human review, audit, microVM
```

**Example 3: Customer Support Bot**
```
Input:     4 (open customer input)
Output:    3 (affects customers)
Data:      2 (customer data)
Model:     1 (constrained)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: 10 (MEDIUM) â† Standard guardrails
```

---

## ğŸ›¡ï¸ Auto-Enabled Guardrails by Risk Level

### LOW Risk (0-4)

```
âœ“ Input validation (basic)
âœ“ Output validation (basic)
âœ“ Logging (info level)
âœ“ Error handling
```

**Setup:** 30 minutes (just add basic checks)

---

### MEDIUM Risk (5-10)

```
âœ“ Everything from LOW, plus:
âœ“ Prompt injection detection (check with separate LLM call)
âœ“ Content filtering (output PII scan)
âœ“ Rate limiting (per user/IP)
âœ“ Audit logging (who, what, when)
âœ“ Input sanitization
```

**Setup:** 4-8 hours (add security layer)

---

### HIGH Risk (11-17)

```
âœ“ Everything from MEDIUM, plus:
âœ“ Human approval for critical actions
âœ“ Comprehensive audit logging (immutable)
âœ“ Encryption (at rest + in transit)
âœ“ Multi-factor verification
âœ“ Rollback capabilities
âœ“ MicroVM isolation (Kata Containers/gVisor)
âœ“ Distributed tracing (OpenTelemetry)
âœ“ Cost tracking per request
âœ“ Real-time alerting
```

**Setup:** 2-4 weeks (enterprise-grade)

---

## ğŸŒ Deployment Platform Matrix (February 2026)

### Decision Guide

| Platform | Best For | Resume Value | Cost | Setup Time | Tier |
|----------|----------|--------------|------|-----------|------|
| **Railway** | Ship MVP this week | â­â­ | $5-50/mo | 30 min | Option A |
| **Google Cloud Run** | Get hired at startups | â­â­â­â­â­ | $20-200/mo | 1 hour | Option B |
| **Azure Container Apps** | Get hired at enterprise | â­â­â­â­â­ | $50-300/mo | 2 hours | Option B |
| **Fly.io** | Global latency + real-time | â­â­â­ | $20-150/mo | 1 hour | Option A/B |
| **Northflank** | Maximum security (microVM) | â­â­â­â­ | $100-500/mo | 3 hours | Option B |

### Decision Rules

- **Speed:** Railway (Option A)
- **Career:** Azure/GCP + Terraform (Option B)
- **Security:** Northflank (Option B)
- **Global:** Fly.io (Option A/B)

---

## ğŸ—ï¸ Architecture Decision Matrix

### By Scale

| Scale | Users | Pattern | Setup | Cost | Complexity |
|-------|-------|---------|-------|------|------------|
| **Tiny** | <100 | Single Lambda + DB | 1 hour | <$10/mo | â­ |
| **Small** | 100-1K | Monolith + DB | 4 hours | $20-50/mo | â­â­ |
| **Medium** | 1K-10K | Modular monolith + cache | 1 day | $50-200/mo | â­â­â­ |
| **Large** | 10K+ | Multi-container + orchestration | 1 week | $500+/mo | â­â­â­â­â­ |

### By Problem Type

| Problem | Architecture | Tools | Risk |
|---------|--------------|-------|------|
| Research/Analysis | Monolith | Local adapters only | LOW-MEDIUM |
| Data Processing | Monolith or Modular | Local DB, cache | MEDIUM |
| Real-time Chat | Monolith | WebSockets, local state | MEDIUM |
| Code Generation | Monolith or Multi-container | Sandbox isolation, MCP | HIGH |
| Multi-step Workflows | Modular monolith | Worker queue, state machine | MEDIUM-HIGH |

---

## ğŸ› ï¸ Easy Swapping Patterns (No Rewrites!)

### Pattern 1: Swap LLM Models (1 line)

```python
# config/llm.py
llm = ChatOpenAI(model="gpt-4")              # OpenAI
llm = ChatAnthropic(model="claude-3-opus")   # Claude
llm = ChatGoogle(model="gemini-pro")         # Google
```

---

### Pattern 2: Swap Tools (Hybrid Pattern)

```python
# app/factory.py
def get_database():
    if os.getenv("USE_MCP") == "true":
        return MCPDatabaseAdapter()     # Sandboxed, safe
    else:
        return LocalPostgresAdapter()   # Fast, local
```

---

### Pattern 3: Swap Databases (1 env var)

```bash
# .env
DATABASE_TYPE=postgresql    # PostgreSQL
DATABASE_TYPE=qdrant        # Vector DB
DATABASE_TYPE=sqlite        # Local dev
```

---

### Pattern 4: Swap Workers (Local â†’ Distributed)

```python
# config/scale.yaml
workers:
  enabled: false            # Run locally
  # Change to: true         # Run distributed (Celery)
```

---

## ğŸ§ª Testing Requirements

### Coverage Targets

```
Unit Tests:        60-70%  (isolated, all mocked)
Integration Tests: 20-30%  (real components, mocked externals)
E2E Tests:         5-10%   (everything real)

TARGET: 80%+ total coverage
```

### Must Include

- âœ“ Security tests (injection, auth, PII)
- âœ“ Integration tests (components work together)
- âœ“ Tooling tests (verify MCP/Local switching)
- âœ“ Performance tests (guardrails don't choke)
- âœ“ Error handling (graceful degradation)

### Command Reference

```bash
# Run all tests
pytest

# With coverage
pytest --cov=app --cov-report=html

# Watch mode (auto-rerun on change)
pytest-watch

# Only integration tests
pytest tests/integration/
```

---

## ğŸš€ Deployment Checklist

**Before going to production:**

- [ ] **Tests:** 80%+ coverage (Unit + Integration)
- [ ] **Infra:** Defined in Terraform ([06_INFRASTRUCTURE_AS_CODE.md](./06_INFRASTRUCTURE_AS_CODE.md))
- [ ] **Tools:** MCP sidecars configured (if using)
- [ ] **Observability:** OpenTelemetry tracing enabled
- [ ] **Context:** `.claude-context.md` up to date
- [ ] **Security:** All guardrails enabled per risk score
- [ ] **Secrets:** Using environment variables, not hardcoded
- [ ] **Database:** Migrations tested, rollback plan
- [ ] **Monitoring:** Alerts configured for failures
- [ ] **Documentation:** README + runbook for ops team

---

## ğŸ” Troubleshooting Quick Fixes

| Problem | Solution | Reference |
|---------|----------|-----------|
| **Connecting external tools** | Use MCP Bridge (hybrid pattern) | See "Easy Swapping" above |
| **Version conflicts** | Use flexible versions (>=) | [03_DEPENDENCY_MANAGEMENT.md](./03_DEPENDENCY_MANAGEMENT.md) |
| **Claude losing context** | Update `.claude-context.md` daily | [05_CLAUDE_CONTEXT_AND_BUGS.md](./05_CLAUDE_CONTEXT_AND_BUGS.md) |
| **Deployment errors** | Check Terraform state | [06_INFRASTRUCTURE_AS_CODE.md](./06_INFRASTRUCTURE_AS_CODE.md) |
| **Agent stuck in loop** | Check OpenTelemetry traces | [02_COMPLETE_GUIDE.md](./02_COMPLETE_GUIDE.md) Section 5.6 |
| **Cost growing too fast** | Adjust `scale.yaml` settings | [07_CONFIGURATION_CONTROL.md](./07_CONFIGURATION_CONTROL.md) |
| **Bugs repeating** | Track in `.bugs_tracker.md` | [05_CLAUDE_CONTEXT_AND_BUGS.md](./05_CLAUDE_CONTEXT_AND_BUGS.md) |

---

## âœ… Success Indicators

You're using this framework correctly when:

âœ… Every project starts with 7-step process (Discovery â†’ Deploy)

âœ… Risk scores calculated BEFORE architecture decisions

âœ… `.claude-context.md` updated after every session

âœ… Guardrails enabled appropriate to risk level

âœ… Infrastructure defined in Terraform (never manual clicks)

âœ… Tests at 80%+ coverage from day 1

âœ… Observability (OTEL) included in production agents

âœ… Claude Code/Cursor asks about risk score first

âœ… Deployment platform chosen from matrix (not random)

---

## ğŸ¤– For Claude Code/Cursor (Explicit Instructions)

When Robert asks "Let's build [thing]":

### Always Do First

1. **Ask:** "What's your risk score? (0-17)"
   - Help calculate using Risk Scoring Formula above
   - This determines EVERYTHING that follows

2. **Ask:** "What platform?" 
   - Reference Platform Matrix above
   - Default: Railway (MVP) or Azure/GCP (Production)

3. **Ask:** "Architecture?"
   - Reference Architecture Decision Matrix above
   - Match to scale + problem type

### Always Include

- âœ… Risk score in analysis (drives guardrails)
- âœ… Appropriate guardrails (from table above)
- âœ… Test coverage strategy (80%+ target)
- âœ… Infrastructure reference ([06_INFRASTRUCTURE_AS_CODE.md](./06_INFRASTRUCTURE_AS_CODE.md))

### When You See Patterns

- Code swapping needed? â†’ Show "Easy Swapping" patterns
- Performance issues? â†’ Suggest deployment from matrix
- Test coverage low? â†’ Reference Testing Requirements above
- Unsure about architecture? â†’ Use Architecture Decision Matrix

---

## ğŸ“‹ Quick Reference Cards

### Print These & Pin Them

**Card 1: Risk Scoring (Pocket Size)**
```
RISK = Input (0-5) + Output (0-5) + Data (0-4) + Model (0-3)
0-4:   LOW      (Basic validation)
5-10:  MEDIUM   (+ Rate limiting)
11-17: HIGH     (+ Human approval)
```

**Card 2: 7-Step Process**
```
1. DISCOVERY (What problem?)
2. RISK SCORING (0-17)
3. GUARDRAILS (What to enable?)
4. ARCHITECTURE (Monolith? Multi?)
5. TOOLING (Local vs MCP?)
6. IMPLEMENTATION (Build + test)
7. DEPLOY & MONITOR (Terraform + OTEL)
```

**Card 3: Platform Picker**
```
Ship fast? â†’ Railway
Get hired? â†’ GCP/Azure
Secure? â†’ Northflank
Global? â†’ Fly.io
```

---

## ğŸ”„ When to Reference This File

- Before architecture decisions (use matrices)
- During implementation (use formulas)
- Before testing (check coverage targets)
- Before deploying (use deployment checklist)
- When debugging (use troubleshooting table)
- When Claude asks "What should we do?" (use 7-step process)

---

## ğŸ“Œ File Meta

**Version:** 1.2.0  
**Released:** February 14, 2026  
**Status:** Production Ready âœ…  
**Last Reviewed:** February 14, 2026  
**Part of:** 8-doc AI Agent Framework  

**Principles Applied:** See [MERGE_PRINCIPLES_LOCKED.md](./MERGE_PRINCIPLES_LOCKED.md)

---

**Use this. Reference it daily. The best tools are the ones you actually use.** ğŸ¯